title: "Phosphorus Traits"
author: "Jay T. Lennon, Mario Muscarella, Kali Bird"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
  - \usepackage{array}
output: pdf_document
geometry: margin=2.54cm
---

Generalist and specialist strategies of phosphorus acquistion by aquatic bacteria 

```{r}
rm(list=ls())
getwd()
setwd("~/GitHub/PhosTrait")
```

Load package for writing figures
```{r}
require("png")
require("vegan")
require("pvclust")
require("mclust")
require("fpc")
```

Load data and standardize 
```{r}
# Raw growth rate data
gr.data <- read.csv("data/grraw.csv", sep=",", header=TRUE)
str(gr.data)
colnames(gr.data)[1]<-"isolate"

# Data standardizing - log10 tranformation
log.gr <- log10(gr.data[,2:19]+1)

# Data standardizing - divide by sum of species growth
gr.std <- gr.data[,2:19] / (apply(gr.data[,2:19], 1, sum))

# Choose data for clustering
data <- gr.std
```

Hierarchical clustering
```{r}
# Identify distance metric
dist <- "euclidean" 
    # manhattan, correlation, uncentered,
    # abscor, euclidean

# Identify agglomerative method
clust <- "average"   
    # complete = furthest neighbor; compact clusters, sensitive to outliers
    # average = UPGMA; considered robust
    # ward.D = popular, but makes clusters of equal size and sensitive to outliers
    # ward.D2 = dissimilarities are squared before clustering
    # mcquitty
    # median = downweights outliers
    # centroid = fairly robust
    # single = nearest neighbor; chaining problem
                    
# Peform hierarchical cluster analysis (reduce nboot to 100 when playing)
pv.clust <- pvclust(data, nboot = 10000, method.dist = dist, 
                      method.hclust = clust)
```

Model-based Bayesian approach to identify clusters
```{r}
# Not entirely sure how this works, but should help ID number of clusters
mv.clust <- Mclust(data)
plot(mv.clust) # plot results
summary(mv.clust)
```

Plotting
```{r}
# Initiate file for figure
png(filename="~/GitHub/PhosTrait/figures/Cluster.png",
    width = 1200, height = 1200, res = 96*2)

# Make plot
plot(pv.clust, main = paste(dist, clust, sep = " "), cex = 1.0, 
     cex.pv = 0.75, col.pv= c("red", "black", "gray"), 
     print.pv = TRUE, print.num = FALSE)

# AU = "approximately unbiased" p-value 
# "Clusters that are highly supported by the data will have large p values."
# BP = "bootstrap probability"

# Highlight clusters based on p-values
pvrect(pv.clust, alpha = 0.95, type="geq") 

dev.off()
graphics.off() # shuts down open devices
```


Validating cluster solutions
```{r}
# compare 2 cluster solutions
cluster.stats(d, fit1$cluster, fit2$cluster)

# haven't tried this yet...

# where d is a distance matrix among objects, and fit1$cluster and fit$cluster are integer vectors containing classification results from two different clusterings of the same data.